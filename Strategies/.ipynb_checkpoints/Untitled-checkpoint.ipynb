{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import sys\n",
    "import os\n",
    "BASE_DIR = os.path.abspath(os.path.join('..'))  # je≈õli notebook w Strategies/notebook\n",
    "sys.path.append(BASE_DIR)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import MetaTrader5 as mt5\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import config\n",
    "\n",
    "def get_live_data(symbol, timeframe, candle_lookback):\n",
    "\n",
    "    if not mt5.initialize():\n",
    "        raise RuntimeError(f\"MT5 initialize failed: {mt5.last_error()}\")\n",
    "\n",
    "    if not mt5.symbol_select(symbol, True):\n",
    "        mt5.symbol_select(symbol, False)  # Deselect\n",
    "        time.sleep(0.5)\n",
    "        if not mt5.symbol_select(symbol, True):\n",
    "            raise RuntimeError(f\"Still can't select symbol: {symbol}\")\n",
    "\n",
    "    rates = mt5.copy_rates_from_pos(symbol, timeframe, 0, candle_lookback)\n",
    "\n",
    "    if rates is None or len(rates) == 0:\n",
    "        raise ValueError(\"Brak danych dla podanego zakresu dat.\")\n",
    "\n",
    "    df = pd.DataFrame(rates)\n",
    "\n",
    "    df['time'] = pd.to_datetime(df['time'], unit='s', utc=True)\n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "def pandas_freq_from_timeframe(tf: str) -> str:\n",
    "    mapping = {\n",
    "        'H1': '1h',\n",
    "        'H4': '4h',\n",
    "        'D1': '1d',\n",
    "        'M1': '1min',\n",
    "        'M5': '5min',\n",
    "        'M15': '15min',\n",
    "    }\n",
    "    return mapping.get(tf.upper(), tf)\n",
    "\n",
    "def get_data(symbol, timeframe, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Pobiera dane z MetaTrader 5 dla wybranego symbolu i przedzia≈Çu czasowego.\n",
    "\n",
    "    Args:\n",
    "        symbol (str): np. 'EURUSD'\n",
    "        timeframe (mt5.TIMEFRAME_*): np. mt5.TIMEFRAME_H1\n",
    "        start_date (datetime): data poczƒÖtkowa\n",
    "        end_date (datetime): data ko≈Ñcowa\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: dane OHLC + wolumen z datami\n",
    "    \"\"\"\n",
    "    # Inicjalizacja\n",
    "    if not mt5.initialize():\n",
    "        raise RuntimeError(f\"MT5 initialize failed: {mt5.last_error()}\")\n",
    "\n",
    "    # Pr√≥ba w≈ÇƒÖczenia symbolu\n",
    "    if not mt5.symbol_select(symbol, True):\n",
    "        time.sleep(0.5)\n",
    "        if not mt5.symbol_select(symbol, True):\n",
    "            mt5.shutdown()\n",
    "            raise RuntimeError(f\"Nie mo≈ºna wybraƒá symbolu: {symbol}\")\n",
    "\n",
    "    # Pobranie danych\n",
    "    rates = mt5.copy_rates_range(symbol, timeframe, start_date, end_date)\n",
    "    if rates is None or len(rates) == 0:\n",
    "        mt5.shutdown()\n",
    "        raise ValueError(f\"Brak danych dla {symbol} w podanym zakresie dat.\")\n",
    "\n",
    "    # Konwersja do DataFrame\n",
    "    df = pd.DataFrame(rates)\n",
    "    df['time'] = pd.to_datetime(df['time'], unit='s')\n",
    "    df = df[['time', 'open', 'high', 'low', 'close', 'tick_volume']]\n",
    "\n",
    "    # Zako≈Ñczenie po≈ÇƒÖczenia\n",
    "    mt5.shutdown()\n",
    "\n",
    "    return df\n",
    "\n",
    "def merge_informative_data(df: pd.DataFrame, timeframe: str, informative_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    freq = pandas_freq_from_timeframe(timeframe)\n",
    "    time_col = f'time_{timeframe}'\n",
    "\n",
    "    if df['time'].dt.tz is None:\n",
    "        df['time'] = df['time'].dt.tz_localize(config.SERVER_TIMEZONE)\n",
    "    else:\n",
    "        df['time'] = df['time'].dt.tz_convert(config.SERVER_TIMEZONE)\n",
    "    df[time_col] = df['time'].dt.tz_convert(config.SERVER_TIMEZONE).dt.floor(freq)\n",
    "\n",
    "\n",
    "    informative_df = informative_df.rename(columns={\n",
    "        col: f\"{col}_{timeframe}\" for col in informative_df.columns if col != 'time'\n",
    "    })\n",
    "\n",
    "    merged = df.merge(\n",
    "        informative_df,\n",
    "        left_on=time_col,\n",
    "        right_on='time',\n",
    "        how='left'\n",
    "    )\n",
    "    #print(f\"[merge_informative_data] Merged dataframe length: {len(merged)}\")\n",
    "\n",
    "    return merged.drop(columns=['time'], errors='ignore')\n",
    "\n",
    "\n",
    "\n",
    "data = get_data(\"EURUSD\", mt5.TIMEFRAME_M5, datetime(2025,1,1), datetime(2025,10,20))\n",
    "data_H1 = get_data(\"EURUSD\", mt5.TIMEFRAME_H1, datetime(2025,1,1), datetime(2025,10,20))"
   ],
   "id": "c82656a196166e0a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "from utils.decorators import informative\n",
    "from TechnicalAnalysis.PointOfInterestSMC.core import SmartMoneyConcepts\n",
    "from TechnicalAnalysis.SessionsSMC.core import SessionsSMC\n",
    "\n",
    "import talib.abstract as ta\n",
    "\n",
    "def get_informative_dataframe(symbol, timeframe: str, startup_candle_count: int) -> pd.DataFrame:\n",
    "    freq = pandas_freq_from_timeframe(timeframe)\n",
    "    tf_minutes = pd.to_timedelta(freq).total_seconds() / 60\n",
    "    extra_minutes = tf_minutes * startup_candle_count\n",
    "\n",
    "    start_time = pd.to_datetime(config.TIMERANGE['start']).tz_localize(config.SERVER_TIMEZONE) - pd.to_timedelta(extra_minutes, unit='m')\n",
    "    end_time = pd.to_datetime(config.TIMERANGE['end']).tz_localize(config.SERVER_TIMEZONE)\n",
    "\n",
    "\n",
    "\n",
    "    df = get_live_data(\n",
    "        symbol,\n",
    "        getattr(mt5, f\"TIMEFRAME_{timeframe}\"),\n",
    "        6000\n",
    "    )\n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "def populate_informative_indicators(obj_with_df_and_symbol):\n",
    "    for attr_name in dir(obj_with_df_and_symbol):\n",
    "        attr = getattr(obj_with_df_and_symbol, attr_name)\n",
    "        if callable(attr) and getattr(attr, '_informative', False):\n",
    "            timeframe = attr._informative_timeframe\n",
    "            if timeframe not in obj_with_df_and_symbol.informative_dataframes:\n",
    "                informative_df = get_informative_dataframe(\n",
    "                    symbol=obj_with_df_and_symbol.symbol,\n",
    "                    timeframe=timeframe,\n",
    "                    startup_candle_count=obj_with_df_and_symbol.startup_candle_count\n",
    "                )\n",
    "                informative_df = attr(df=informative_df.copy())\n",
    "                obj_with_df_and_symbol.informative_dataframes[timeframe] = informative_df\n",
    "            else:\n",
    "                informative_df = obj_with_df_and_symbol.informative_dataframes[timeframe]\n",
    "\n",
    "            obj_with_df_and_symbol.df = merge_informative_data(\n",
    "                obj_with_df_and_symbol.df,\n",
    "                timeframe,\n",
    "                informative_df\n",
    "            )\n",
    "\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "def merge_signals(signal_list):\n",
    "    if not signal_list:\n",
    "        return None\n",
    "    direction = signal_list[0][0]\n",
    "    reasons = sorted(set(sig[1] for sig in signal_list))\n",
    "    merged_reason = \"_\".join(reasons)\n",
    "    return (direction, merged_reason)\n",
    "\n",
    "def merge_levels(level_list, direction=\"long\", close_price=None):\n",
    "    if not level_list:\n",
    "        return None\n",
    "\n",
    "    min_distance_ratio = 0.0005  # 0.05%\n",
    "    max_sl_ratio = 0.003         # 0.3%\n",
    "    min_sl_ratio = 0.001         # 0.1%\n",
    "\n",
    "    # üîπ Zbierz unikalne tagi (dla informacji)\n",
    "    tags = [level.get(\"tag\", \"?\") for level in level_list]\n",
    "    combined_tag = \"_\".join(sorted(set(tags)))\n",
    "\n",
    "    sl_all, tp1_all, tp2_all = [], [], []\n",
    "\n",
    "    # üîπ Zbierz wszystkie poziomy SL/TP z level[\"extra\"]\n",
    "    for level in level_list:\n",
    "        extra = level.get(\"extra\", {}) or {}\n",
    "        sl_val = extra.get(\"sl\")\n",
    "        tp1_val = extra.get(\"tp1\")\n",
    "        tp2_val = extra.get(\"tp2\")\n",
    "\n",
    "        if sl_val is not None:\n",
    "            sl_all.append((level[\"source\"], sl_val))\n",
    "        if tp1_val is not None:\n",
    "            tp1_all.append((level[\"source\"], tp1_val))\n",
    "        if tp2_val is not None:\n",
    "            tp2_all.append((level[\"source\"], tp2_val))\n",
    "\n",
    "    # üîπ Uzupe≈Çnij brakujƒÖce poziomy (na podstawie ceny close)\n",
    "    if close_price is not None:\n",
    "        if not sl_all:\n",
    "            sl_value = close_price - (close_price * min_distance_ratio * 1.2) if direction == \"long\" else close_price + (close_price * min_distance_ratio * 1.2)\n",
    "            sl_all.append((\"auto\", sl_value))\n",
    "        if not tp1_all:\n",
    "            tp1_value = close_price + (close_price * min_distance_ratio * 2) if direction == \"long\" else close_price - (close_price * min_distance_ratio * 2)\n",
    "            tp1_all.append((\"auto\", tp1_value))\n",
    "        if not tp2_all:\n",
    "            tp2_value = close_price + (close_price * min_distance_ratio * 3) if direction == \"long\" else close_price - (close_price * min_distance_ratio * 3)\n",
    "            tp2_all.append((\"auto\", tp2_value))\n",
    "\n",
    "    # üîπ Wybierz finalne warto≈õci\n",
    "    if direction == \"long\":\n",
    "        sl_final = min(sl_all, key=lambda x: x[1])\n",
    "        tp1_final = max(tp1_all, key=lambda x: x[1])\n",
    "        tp2_final = max(tp2_all, key=lambda x: x[1])\n",
    "    else:\n",
    "        sl_final = max(sl_all, key=lambda x: x[1])\n",
    "        tp1_final = min(tp1_all, key=lambda x: x[1])\n",
    "        tp2_final = min(tp2_all, key=lambda x: x[1])\n",
    "\n",
    "    # üîπ Walidacja odleg≈Ço≈õci SL / TP wzglƒôdem ceny close\n",
    "    if close_price is not None:\n",
    "        risk = abs(close_price - sl_final[1])\n",
    "        max_allowed_risk = close_price * max_sl_ratio\n",
    "        min_sl = close_price * min_sl_ratio\n",
    "\n",
    "        # Zbyt ma≈Çy SL ‚Üí wymu≈õ minimalny dystans\n",
    "        if risk < min_sl:\n",
    "            new_sl_price = close_price - min_sl if direction == \"long\" else close_price + min_sl\n",
    "            sl_final = (\"min_0.1%\", new_sl_price)\n",
    "\n",
    "        # RR check i korekta TP\n",
    "        risk = abs(close_price - sl_final[1])\n",
    "        reward_tp1 = abs(tp1_final[1] - close_price)\n",
    "        reward_tp2 = abs(tp2_final[1] - close_price)\n",
    "\n",
    "        # Wyr√≥wnaj TP1/TP2 dla lepszego RR\n",
    "        if reward_tp1 / risk < 2:\n",
    "            new_tp1 = close_price + risk * 2 if direction == \"long\" else close_price - risk * 2\n",
    "            tp1_final = (\"RR_1:2\", new_tp1)\n",
    "\n",
    "        if reward_tp2 / risk < 4:\n",
    "            new_tp2 = close_price + risk * 4 if direction == \"long\" else close_price - risk * 4\n",
    "            tp2_final = (\"RR_1:4\", new_tp2)\n",
    "\n",
    "        if reward_tp1 / risk > 3:\n",
    "            new_tp1 = close_price + risk * 3 if direction == \"long\" else close_price - risk * 3\n",
    "            tp1_final = (\"RR_1:3\", new_tp1)\n",
    "\n",
    "        if reward_tp2 / risk > 6:\n",
    "            new_tp2 = close_price + risk * 6 if direction == \"long\" else close_price - risk * 6\n",
    "            tp2_final = (\"RR_1:6\", new_tp2)\n",
    "\n",
    "    return (\n",
    "        (\"SL\", sl_final[1], f\"SL_{sl_final[0]}_{combined_tag}\"),\n",
    "        (\"TP\", tp1_final[1], f\"TP1_{tp1_final[0]}_{combined_tag}\"),\n",
    "        (\"TP\", tp2_final[1], f\"TP2_{tp2_final[0]}_{combined_tag}\")\n",
    "    )\n",
    "\n",
    "\n",
    "class Poi:\n",
    "    def __init__(self, df: pd.DataFrame, symbol, startup_candle_count: int = 600):\n",
    "        self.startup_candle_count = startup_candle_count\n",
    "        self.df = df.copy()\n",
    "        self.symbol = symbol\n",
    "        self.informative_dataframes = {}\n",
    "        # Inicjalizacja klasy SmartMoneyConcepts\n",
    "        \n",
    "        self.smc = SmartMoneyConcepts(self.df)\n",
    "        self.sessions = SessionsSMC(self.df)\n",
    "        self.sessions_h1 = None\n",
    "\n",
    "    @informative('H1')\n",
    "    def populate_indicators_H1(self, df: pd.DataFrame):\n",
    "        \n",
    "        df['idx'] = df.index\n",
    "        df['atr'] = ta.ATR(df, 14)\n",
    "\n",
    "         # Aktualizujemy niezale≈ºne instancje\n",
    "        self.smc.df = df.copy()\n",
    "        self.smc.find_validate_zones(tf=\"H1\")\n",
    "\n",
    "        self.sessions_h1 = SessionsSMC(df.copy())\n",
    "        self.sessions_h1.df = self.sessions_h1.calculate_previous_ranges()\n",
    "\n",
    "\n",
    "        # Zwracamy co≈õ, by merge m√≥g≈Ç zadzia≈Çaƒá\n",
    "        return df\n",
    "\n",
    "        \n",
    "\n",
    "    def populate_indicators(self):\n",
    "        self.df = self.df.rename(columns={'time_x': 'time'})\n",
    "        if 'time_y' in self.df.columns:\n",
    "            self.df = self.df.drop(columns=['time_y'])\n",
    "\n",
    "\n",
    "        self.df['idx'] = self.df.index\n",
    "        self.df['atr'] = ta.ATR(self.df, 14)\n",
    "\n",
    "        # Aktualizujemy r√≥wnie≈º na M5\n",
    "        self.smc.df = self.df.copy()\n",
    "        self.smc.find_validate_zones(tf=\"M5\")\n",
    "        self.smc.detect_reaction()\n",
    "\n",
    "        self.sessions.df = self.df.copy()\n",
    "        self.sessions.calculate_sessions_ranges()\n",
    "        \n",
    "\n",
    "        if self.sessions_h1 is not None:\n",
    "            self.sessions.df = pd.merge_asof(\n",
    "                self.sessions.df.sort_values('time'),\n",
    "                self.sessions_h1.df.sort_values('time'),\n",
    "                on='time',\n",
    "                direction='backward',\n",
    "                suffixes=('', '_H1')\n",
    "            )\n",
    "\n",
    "        self.sessions.detect_session_type()\n",
    "        self.sessions.detect_signals()\n",
    "\n",
    "\n",
    "        return self.df\n",
    "\n",
    "    def merge_external_dfs(self):\n",
    "        \"\"\"\n",
    "        ≈ÅƒÖczy dane z:\n",
    "        - self.smc.df\n",
    "        - self.sessions.df\n",
    "        - sygna≈Çy z self.sessions.detect_signals()\n",
    "    \n",
    "        Pomija kolumny ju≈º obecne w self.df.\n",
    "        \"\"\"\n",
    "        base = self.df.copy()\n",
    "    \n",
    "        # --- ≈ÅƒÖczenie z self.smc.df ---\n",
    "        if hasattr(self, \"smc\") and hasattr(self.smc, \"df\"):\n",
    "            smc_df = self.smc.df.copy()\n",
    "            new_cols = [c for c in smc_df.columns if c not in base.columns]\n",
    "            if new_cols:\n",
    "                base = base.merge(smc_df[['time'] + new_cols], on='time', how='left', validate='1:1')\n",
    "    \n",
    "        # --- ≈ÅƒÖczenie z self.sessions.df ---\n",
    "        if hasattr(self, \"sessions\") and hasattr(self.sessions, \"df\"):\n",
    "            sessions_df = self.sessions.df.copy()\n",
    "            new_cols = [c for c in sessions_df.columns if c not in base.columns]\n",
    "            if new_cols:\n",
    "                base = base.merge(sessions_df[['time'] + new_cols], on='time', how='left', validate='1:1')\n",
    "\n",
    "        \n",
    "    \n",
    "        self.df = base\n",
    "\n",
    "        print(f\"Kolumny self.df: {list(self.df.columns)}\")\n",
    "\n",
    "    def populate_entry_trend(self):\n",
    "        \"\"\"\n",
    "        ≈ÅƒÖczy sygna≈Çy z:\n",
    "        - struktur HTF (breaker, OB, FVG)\n",
    "        - struktur LTF (breaker, OB, FVG)\n",
    "        - sygna≈Ç√≥w sesyjnych z self.sessions.detect_signals()\n",
    "    \n",
    "        Wynik: kolumny `signal_entry` (lista sygna≈Ç√≥w) oraz `levels` (poziomy SL/TP).\n",
    "        \"\"\"\n",
    "    \n",
    "        df = self.df.copy()\n",
    "\n",
    "        # --- 1Ô∏è‚É£ Agregacja stref bullish / bearish dla HTF i LTF ---\n",
    "        df['bullish_breaker_H1'] = df['bullish_breaker_reaction_H1'] | df['bullish_breaker_in_zone_H1']\n",
    "        df['bullish_fvg_H1'] = df['bullish_fvg_reaction_H1'] | df['bullish_fvg_in_zone_H1']\n",
    "        df['bullish_ob_H1'] = df['bullish_ob_reaction_H1'] | df['bullish_ob_in_zone_H1']\n",
    "\n",
    "        df['bullish_breaker'] = df['bullish_breaker_reaction'] | df['bullish_breaker_in_zone']\n",
    "        df['bullish_fvg'] = df['bullish_fvg_reaction'] | df['bullish_fvg_in_zone']\n",
    "        df['bullish_ob'] = df['bullish_ob_reaction'] | df['bullish_ob_in_zone']\n",
    "\n",
    "        htf_zone_long_cols = ['bullish_breaker_H1', 'bullish_ob_H1', 'bullish_fvg_H1']\n",
    "        ltf_zone_long_cols = ['bullish_breaker', 'bullish_ob', 'bullish_fvg']\n",
    "\n",
    "        # --- 1Ô∏è‚É£ Sprawd≈∫, kt√≥re HFT/LTF sƒÖ aktywne ---\n",
    "        df[\"htf_active\"] = df[htf_zone_long_cols].apply(\n",
    "            lambda x: [col.replace(\"bullish_\", \"\").replace(\"_H1\", \"\").upper() for col in x.index if x[col]], axis=1)\n",
    "        df[\"ltf_active\"] = df[ltf_zone_long_cols].apply(\n",
    "            lambda x: [col.replace(\"bullish_\", \"\").upper() for col in x.index if x[col]], axis=1)\n",
    "\n",
    "        # --- 2Ô∏è‚É£ Warunek konfluencji ---\n",
    "        confluence_mask = (\n",
    "            df[\"sessions_signal\"].notna()\n",
    "            & (df[\"htf_active\"].apply(len) > 0)\n",
    "            & (df[\"ltf_active\"].apply(len) > 0)\n",
    "        )\n",
    "\n",
    "        # --- 3Ô∏è‚É£ Tworzymy sygna≈Ç i tag tylko tam, gdzie konfluencja ---\n",
    "        df[\"signal_entry\"] = None\n",
    "        df[\"levels\"] = None\n",
    "        df.loc[confluence_mask, \"signal_entry\"] = df.loc[confluence_mask].apply(\n",
    "            lambda row: {\n",
    "                \"direction\": row[\"sessions_signal\"],\n",
    "                \"tag\": \"_\".join([row[\"session_context\"]] + row[\"htf_active\"] + row[\"ltf_active\"])\n",
    "            }, axis=1\n",
    "        )\n",
    "    \n",
    "        # --- 7Ô∏è‚É£ Zapisz wynik ---\n",
    "        self.df = df\n",
    "\n",
    "        #print(df[\"levels\"])\n",
    "\n",
    "        #print(df[\"signal_entry\"])\n",
    "        \n",
    "        return df\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    def get_bullish_zones(self):\n",
    "        return []\n",
    "\n",
    "    def get_bearish_zones(self):\n",
    "        return []\n",
    "\n",
    "    def get_extra_values_to_plot(self):\n",
    "        return [\n",
    "            #(\"london_high\", self.sessions.df[\"london_main_high\"], \"blue\", \"dot\"),\n",
    "            #(\"london_low\", self.sessions.df[\"london_main_low\"], \"blue\", \"dot\"),\n",
    "            #(\"asia_high\", self.sessions.df[\"asia_main_high\"], \"purple\", \"dot\"),\n",
    "            #(\"asia_low\", self.sessions.df[\"asia_main_low\"], \"purple\", \"dot\"),\n",
    "            #(\"ny_high\", self.sessions.df[\"ny_main_high\"], \"orange\", \"dash\"),\n",
    "            #(\"ny_low\", self.sessions.df[\"ny_main_low\"], \"orange\", \"dash\"),\n",
    "\n",
    "            #(\"PDH\", self.sessions.df[\"PDH\"], \"blue\"),\n",
    "            #(\"PDL\", self.sessions.df[\"PDL\"], \"blue\"),\n",
    "\n",
    "            #(\"PWH\", self.sessions.df[\"PWH\"], \"yellow\"),\n",
    "            #(\"PWL\", self.sessions.df[\"PWL\"], \"yellow\"),\n",
    "        ]\n",
    "\n",
    "    def get_bullish_zones(self):\n",
    "        return [\n",
    "            #(\"Bullish IFVG H1\", self.smc.bullish_ifvg_validated_H1, \"rgba(255, 160, 122, 0.7)\"),\n",
    "            # Pomara≈Ñcz (pozostawiony bez zmian)\n",
    "            # (\"Bullish IFVG\", self.bullish_ifvg_validated, \"rgba(139, 0, 0, 1)\"),\n",
    "\n",
    "            #(\"Bullish FVG H1\", self.smc.bullish_fvg_validated_H1, \"rgba(255, 152, 0, 0.7)\"),  # Jasnoniebieski\n",
    "            # (\"Bullish FVG\", self.bullish_fvg_validated, \"rgba(255, 152, 0, 0.7)\"),             # Ciemnoniebieski\n",
    "\n",
    "            (\"Bullish OB H1\", self.smc.bullish_ob_validated_H1, \"rgba(144, 238, 144, 0.7)\"),  # Jasnozielony\n",
    "            # (\"Bullish OB\", self.bullish_ob_validated, \"rgba(0, 100, 0, 1)\"),           # Ciemnozielony\n",
    "\n",
    "            (\"Bullish Breaker H1\", self.smc.bullish_breaker_validated_H1, \"rgba(173, 216, 230, 0.7)\"),  # Jasnoniebieski\n",
    "            # (\"Bullish Breaker\", self.bullish_breaker_validated, \"rgba(0, 0, 139, 1)\"),             # Ciemnoniebieski\n",
    "\n",
    "            # (\"Bullish GAP \", self.bullish_gap_validated, \"rgba(56, 142, 60, 1)\"),\n",
    "        ]\n",
    "\n",
    "    def get_bearish_zones(self):\n",
    "        return [\n",
    "            # (\"Bearish Breaker\", self.smc.bearish_breaker_validated, \"rgba(64, 64, 64, 1)\"),      # Ciemnoszary\n",
    "             (\"Bearish Breaker H1\", self.smc.bearish_breaker_validated_H1, \"rgba(169, 169, 169, 0.7)\"),  # Jasnoszary\n",
    "\n",
    "            # (\"Bearish OB\", self.smc.bearish_ob_validated, \"rgba(139, 0, 0, 1)\"),                # Ciemnoczerwony\n",
    "             (\"Bearish OB H1\", self.smc.bearish_ob_validated_H1, \"rgba(255, 160, 122, 0.7)\"),       # Jasnoczerwony\n",
    "\n",
    "            # (\"Bearish IFVG H1\", self.smc.bearish_ifvg_validated_H1, \"rgba(139, 0, 0, 1)\"),  # Pomara≈Ñcz (pozostawiony bez zmian)\n",
    "            # (\"Bearish IFVG\", self.smc.bearish_ifvg_validated, \"rgba(255, 160, 122, 0.7)\"),\n",
    "\n",
    "            # (\"Bearish FVG\", self.smc.bearish_fvg_validated, \"rgba(0, 0, 139, 1)\"),      # Ciemnoszary\n",
    "            # (\"Bearish FVG H1\", self.smc.bearish_fvg_validated_H1, \"rgba(173, 216, 230, 0.7)\"),  # Jasnoszary\n",
    "        ]\n",
    "    \n",
    "    def bool_series(self):\n",
    "        return []\n",
    "\n",
    "\n",
    "    def run(self) -> pd.DataFrame:\n",
    "\n",
    "\n",
    "        timings = []  # Lista do przechowywania czas√≥w\n",
    "\n",
    "        def timeit(label, func):\n",
    "            start = time.time()\n",
    "            func()\n",
    "            end = time.time()\n",
    "            duration = end - start\n",
    "            timings.append((label, duration))\n",
    "            #print(f\"{label} finished in {duration:.4f} seconds\")\n",
    "\n",
    "        timeit(\"_populate_informative_indicators\", lambda: populate_informative_indicators(self))\n",
    "        timeit(\"self.populate_indicators()\", lambda: self.populate_indicators())\n",
    "        timeit(\"self.merge_external_dfs()\", lambda: self.merge_external_dfs())\n",
    "        timeit(\"self.populate_entry_trend()\", lambda: self.populate_entry_trend())\n",
    "\n",
    "        # 3Ô∏è‚É£ Zwr√≥ƒá ko≈Ñcowy DataFrame z M5 + H1 scalonymi danymi\n",
    "        print(\"\\n‚è±Ô∏è Profil czasu wykonania:\")\n",
    "        for label, duration in timings:\n",
    "            print(f\"   {label:<40} {duration:.3f}s\")\n",
    "\n",
    "\n",
    "\n",
    "        return self.sessions.df"
   ],
   "id": "870efc402631d3ab"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "073356c1-4d66-461d-95e6-719fc247a905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kolumny self.df: ['time', 'open', 'high', 'low', 'close', 'tick_volume', 'time_H1', 'open_H1', 'high_H1', 'low_H1', 'close_H1', 'tick_volume_H1', 'spread_H1', 'real_volume_H1', 'idx_H1', 'atr_H1', 'idx', 'atr', 'reaction', 'in_zone', 'active_zone_tf', 'active_zone_type', 'active_zone_dir', 'bearish_breaker_in_zone_H1', 'bearish_breaker_reaction_H1', 'bearish_breaker_in_zone', 'bearish_breaker_reaction', 'bearish_fvg_in_zone_H1', 'bearish_fvg_reaction_H1', 'bearish_fvg_in_zone', 'bearish_fvg_reaction', 'bearish_ifvg_in_zone_H1', 'bearish_ifvg_reaction_H1', 'bearish_ifvg_in_zone', 'bearish_ifvg_reaction', 'bearish_ob_in_zone_H1', 'bearish_ob_reaction_H1', 'bearish_ob_in_zone', 'bearish_ob_reaction', 'bullish_breaker_in_zone_H1', 'bullish_breaker_reaction_H1', 'bullish_breaker_in_zone', 'bullish_breaker_reaction', 'bullish_fvg_in_zone_H1', 'bullish_fvg_reaction_H1', 'bullish_fvg_in_zone', 'bullish_fvg_reaction', 'bullish_ifvg_in_zone_H1', 'bullish_ifvg_reaction_H1', 'bullish_ifvg_in_zone', 'bullish_ifvg_reaction', 'bullish_ob_in_zone_H1', 'bullish_ob_reaction_H1', 'bullish_ob_in_zone', 'bullish_ob_reaction', 'asia_main_high', 'asia_main_low', 'killzone_london_high', 'killzone_london_low', 'london_main_high', 'london_main_low', 'killzone_ny_high', 'killzone_ny_low', 'ny_main_high', 'ny_main_low', 'spread', 'real_volume', 'date', 'weekday', 'week', 'year', 'hour', 'monday_high', 'monday_low', 'monday', 'PDH', 'PDL', 'weekly_high', 'weekly_low', 'PWH', 'PWL', 'session', 'sessions_signal', 'session_context']\n",
      "\n",
      "‚è±Ô∏è Profil czasu wykonania:\n",
      "   _populate_informative_indicators         0.213s\n",
      "   self.populate_indicators()               25.930s\n",
      "   self.merge_external_dfs()                0.058s\n",
      "   self.populate_entry_trend()              0.889s\n",
      "no pivot\n"
     ]
    }
   ],
   "source": [
    "from backtesting.plot import plot_trades_with_indicators\n",
    "\n",
    "poi = Poi(df=data, symbol=\"EURUSD\")\n",
    "\n",
    "\n",
    "df_bt = poi.run()\n",
    "\n",
    "\n",
    "\n",
    "#print(\"\\nüìä === INFORMACJE O self.smc.df ===\")\n",
    "#print(f\"Kszta≈Çt: {df_bt.shape}\")\n",
    "#print(f\"Kolumny: {list(df_bt.columns)}\")\n",
    "#print(\"\\nPrzyk≈Çadowe dane:\")\n",
    "#print(df_bt.head(5))\n",
    "\n",
    "         \n",
    "plot_trades_with_indicators(\n",
    "    df_bt,\n",
    "    \"EURUSD\",\n",
    "    bullish_zones=poi.get_bullish_zones(),\n",
    "    bearish_zones=poi.get_bearish_zones(),\n",
    "    extra_series=poi.get_extra_values_to_plot(),\n",
    "    bool_series=poi.bool_series(),\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2e65a6e0-fd66-4156-b94c-c87703fbaedf",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a9365c-6f35-4396-bc53-cee2fe9b7c89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4ef071-3988-4b8f-8a8e-b687330a2adf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a04224-565e-4d13-ba59-767477eb4817",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dc5ef8-3e9d-42c2-8bee-638d4bc2665b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
